'''Adaptive importance sampling algorithm for paper '''
#Import functions
from __future__ import division 
import numpy as np
import scipy
import matplotlib.pyplot as plt
import sys
import matplotlib
from scipy.stats import multivariate_normal
from scipy import integrate
from mpl_toolkits.mplot3d import Axes3D 
from uqPythonSubmit import runGrid
from scipy.integrate import quad

#parameter ranges:
[a_q,b_q] = [0,1] 
[a_M1,b_M1] = [7,100] #in Msun 
[a_a,b_a] = -1,3 #in AU and Log10
dimension = 3


#pdfs initial parameters 
def IMFforNorm(xx):
    return xx**(-2.35)
K1 = 1./(quad(IMFforNorm, a_M1, b_M1)[0])
def prior_M1(x):
	alpha_local = 2.35
	prob_M1 = K1*x**(-alpha_local)
	return prob_M1

def prior_a(x):
	prob_a = (1./(x*np.log(10.)))*(1./(b_a-a_a))
	return prob_a

def prior_q(x):
	prob_q = 1./(b_q-a_q)
	return prob_q


#Sampling from pdf
def sampling_from_IMF(Nsamples): 
	'''returns  N samples distributed to IMF with alpha_local using inverse sampling'''
	alpha_local = 2.35
	samples = ((np.random.uniform(0,1, Nsamples))*(100**(1.-alpha_local) - 7**(1.-alpha_local)) +7**(1-alpha_local))**(1./(1.-alpha_local))
	return samples

def sampling_from_a(Nsamples):
	'''returns  N samples distributed log uniform via inverse sampling'''
	return 10**np.random.uniform(a_a, b_a,Nsamples)

def sampling_from_q(Nsamples):
	'''returns  N samples distributed uniform'''
	return np.random.uniform(a_q, b_q, Nsamples)




#####################
def initial_sampling(N_ones_wanted_ini):
	'''takes samples and evaluates them until N_ones_wanted_ini successful (i.e. hits) samples are found'''
	print('initial sampling starts')
	N_hits_ini = 0
	N_ini_all = 0
	#make lists for parameters from model
	a_ini_1,q_ini_1,M1_ini_1 = [],[],[]
	M1_BH,M2_BH = [],[]
	optimisticCEFlag,RLOFSecondaryAfterCEE = [],[] #check this with Jim Barrett
	gaus_mean_for_ref1 = []
	a_ini_all,q_ini_all,M1_ini_all = [],[],[]
	weights_ini_1 =[]

	#run new initial samples for COMPAS until certain number of successful sample runs are found. 
	while N_hits_ini < N_ones_wanted_ini: 
		samples_ini_M1 = np.random.uniform(7, 100,1) #  sampling_from_IMF(1) #change to IS: 
		samples_ini_a = sampling_from_a(1) 
		samples_ini_q = sampling_from_q(1)
		N_ini_all = N_ini_all + 1
		M1_ini_all.append(samples_ini_M1)
		a_ini_all.append(samples_ini_a)
		q_ini_all.append(samples_ini_q)
		
		
		runGrid('/home/floor/Documents/UQforCOMPAS_2017/CompasUncertaintyQuantification-master/Compas-essentials-10-17/test1',primaryMasses = samples_ini_M1, semiMajorAxes = samples_ini_a, massRatios = samples_ini_q)
		d = np.genfromtxt('/home/floor/Documents/UQforCOMPAS_2017/CompasUncertaintyQuantification-master/Compas-essentials-10-17/test1/allMergers.dat', names=True,skip_header=1)
		if d:
		    mergesInHubbleTimeFlag = d['mergesInHubbleTimeFlag']
		    if (mergesInHubbleTimeFlag == 1): #check if merge in Hubble time
		        stellarType1 = d['stellarType1']
		        if (stellarType1 ==14.0): #check if M1 BH
		            stellarType2 = d['stellarType2']
		            if (stellarType2 ==14.0): #check if M2 = BH
		                M1ZAMS = d['M1ZAMS']
		                M2ZAMS = d['M2ZAMS']
		                a_ini_1.append(d['separationInitial'])
		                q_ini_1.append(M2ZAMS/float(M1ZAMS))
		                M1_ini_1.append(M1ZAMS)
		                M1_BH.append(d['M1'])
		                M2_BH.append(d['M2'])
		                gaus_mean_for_ref1.append([M1_ini_1[-1],a_ini_1[-1],q_ini_1[-1]])
		                optimisticCEFlag.append(d['optimisticCEFlag'])
		                RLOFSecondaryAfterCEE.append(d['RLOFSecondaryAfterCEE'])
		                N_hits_ini = N_hits_ini+1 
		                print samples_ini_M1
		               # print M1_ini_1
		               	print prior_M1(samples_ini_M1[-1])
		                w_temp = prior_M1(samples_ini_M1[-1])/(1./(b_M1-a_M1))
		                weights_ini_1.append(w_temp)
		                print(N_hits_ini)


 	return N_ini_all,M1_ini_1,a_ini_1,q_ini_1,M1_ini_all,a_ini_all,q_ini_all,gaus_mean_for_ref1, M1_BH,M2_BH,optimisticCEFlag,RLOFSecondaryAfterCEE,weights_ini_1




def MonteCarlo_estimator(N_tot,N_ones):
	return (1./N_tot) * N_ones 

def ImportanceSampling_estimator_ini(N_tot_samples,weights):
	print weights 
	print sum(weights)
	ISestimator_ini =(1./N_tot_samples)*sum(weights) 
	return ISestimator_ini 




def ImportanceSampling_estimator_ref1(N_ref1_all,weights_temp):
	#print 'len 1 + len 0 = ', len(weights_0), len(weights_1), 'should equal', N_ref1_all
	ISestimator =  (1./(N_ref1_all))*sum(weights_temp) #* (1./(float(sum(weights_0))+sum(weights_1))) #(1./N_ref1_all)*
	return ISestimator

### REFINED SAMPLING 1 ##########




def refined_1_sampling(N_ini_ones_choice,gaus_mean_for_ref1,N_ini_all):
	''' '''
	print('refinement 1 starts')
	#define the covariance matrix for the gaussians by sigma = average distance between two hits. 
	sigma_squared_M1 = 4*(abs(a_M1-b_M1)/(N_ini_all**(1./dimension)))**2 #factor two to make it a little larger
	sigma_squared_a = 90*(abs(a_a-b_a)/(N_ini_all**(1./dimension)))**2 #whatch out! used to be abs(a_a-b_a)
	sigma_squared_q = 4*(abs(a_q-b_q)/(N_ini_all**(1./dimension)))**2
	cov_M1 = sigma_squared_M1
	cov_a = sigma_squared_a
	cov_q = sigma_squared_q
	cov =  [[sigma_squared_M1, 0, 0], [0, sigma_squared_a, 0], [0, 0, sigma_squared_q]]
	print 'the cov matrix = ', cov
	#make lists for /set parameters
	N_ref1_all = 0 
	a_ref1_1,q_ref1_1,M1_ref1_1 = [],[],[]
	M1_ref1_BH,M2_ref1_BH = [],[]
	optimisticCEFlag_ref1,RLOFSecondaryAfterCEE_ref1 = [],[]
	a_ref1_all,q_ref1_all,M1_ref1_all = [],[],[]
	samples_all_ref1 = []
	samples_1_ref1 = []
	weights_1_for_IS_estimator_ref1 = []
	weights_0_for_IS_estimator_ref1 = []
	# for ref1
	estimator_error =0.5 
	count_outside_parameter_space = 0 
	
	while estimator_error > 0.2:
		''' '''
		for i in range(N_ini_ones_choice): #Jim Barrett; can we do this faster (for loop)?

			sample_ref1_single = multivariate_normal.rvs( mean = gaus_mean_for_ref1[i], cov = cov,size = 1) #np.random.multivariate_normal(gaus_mean_for_ref1[i], cov, 1)[0]  # take one sample from Gauss around one mean do this for all i
			#rejection sampling: 
			#while
			samples_all_ref1.append(sample_ref1_single)
			M1_ref1_all.append(sample_ref1_single[0]) 
			a_ref1_all.append(sample_ref1_single[1])
			q_ref1_all.append(sample_ref1_single[2]) 
			
			if (sample_ref1_single[0] < a_M1) or (sample_ref1_single[0] > b_M1) or (sample_ref1_single[1] < 10.**a_a) or (sample_ref1_single[1] > 10.**b_a) or (sample_ref1_single[2] < a_q) or (sample_ref1_single[2] > b_q):
				#sample_ref1_single = multivariate_normal.rvs( mean = gaus_mean_for_ref1[i], cov = cov,size = 1) #np.random.multivariate_normal(gaus_mean_for_ref1[i], cov, 1)[0]
				count_outside_parameter_space += 1

			#print sample_ref1_single

			else:
			#print 'sample ref single', sample_ref1_single
			#run compas with not rejected sample point
				runGrid('/home/floor/Documents/UQforCOMPAS_2017/CompasUncertaintyQuantification-master/Compas-essentials-10-17/test1',primaryMasses = np.array([sample_ref1_single[0]]), semiMajorAxes = np.array([sample_ref1_single[1]]), massRatios = np.array([sample_ref1_single[2]]))
				d = np.genfromtxt('/home/floor/Documents/UQforCOMPAS_2017/CompasUncertaintyQuantification-master/Compas-essentials-10-17/test1/allMergers.dat', names=True,skip_header=1)
				if d:
					#print 'hello2'
					mergesInHubbleTimeFlag = d['mergesInHubbleTimeFlag']
					stellarType1 = d['stellarType1']
					stellarType2 = d['stellarType2']
					if (mergesInHubbleTimeFlag == 1) and (stellarType1 ==14.0) and (stellarType2 ==14.0):
						M1ZAMS = d['M1ZAMS']
						M2ZAMS = d['M2ZAMS']
						M1_ref1_1.append(M1ZAMS)
						a_ref1_1.append(d['separationInitial'])
						q_ref1_1.append(M2ZAMS/float(M1ZAMS))
						M1_ref1_BH.append(d['M1'])
						M2_ref1_BH.append(d['M2'])
						samples_1_ref1.append([M1_ini_1[-1],a_ini_1[-1],q_ini_1[-1]]) #this are the samples combined as (M1,a,q)
						optimisticCEFlag_ref1.append(d['optimisticCEFlag'])
						RLOFSecondaryAfterCEE_ref1.append(d['RLOFSecondaryAfterCEE'])

						prior_sample_1 = prior_M1(float(M1_ref1_1[-1]))*prior_a(float(a_ref1_1[-1]))*prior_q(float(q_ref1_1[-1])) 
						instrumental_sample_1 = (multivariate_normal.pdf(sample_ref1_single,gaus_mean_for_ref1[i],cov))
						#instrumental_sample_1 = calculates_mixturePDF(N_ini_ones_choice,gaus_mean_for_ref1,samples_1_ref1[-1],cov)
						#print('IS prob')
						weights_1_for_IS_estimator_ref1.append(prior_sample_1/float(instrumental_sample_1))
						#print(weights_1_for_IS_estimator_ref1[-1])
						N_ref1_all +=1	
						#print 'at GW', N_ref1_all
					else:
						prior_sample_0 = 1 #prior_M1(float(sample_ref1_single[0]))*prior_a(float(sample_ref1_single[1]))*prior_q(float(sample_ref1_single[2])) 
						#instrumental_sample_0 = (multivariate_normal.pdf(sample_ref1_single,gaus_mean_for_ref1[i],cov))
						instrumental_sample_0 = 1
						weights_0_for_IS_estimator_ref1.append(prior_sample_0/float(instrumental_sample_0))
						#print weights_0_for_IS_estimator_ref1[-1]
						N_ref1_all +=1
						#print 'at no GW but if d ', N_ref1_all
				
				else:
					prior_sample_0 = 1#prior_M1(float(sample_ref1_single[0]))*prior_a(float(sample_ref1_single[1]))*prior_q(float(sample_ref1_single[2])) 
					#instrumental_sample_0 = (multivariate_normal.pdf(sample_ref1_single,gaus_mean_for_ref1[i],cov))
					instrumental_sample_0 = 1
					weights_0_for_IS_estimator_ref1.append(prior_sample_0/float(instrumental_sample_0))
					#print weights_0_for_IS_estimator_ref1[-1]
					N_ref1_all +=1
					#print 'at no GW', N_ref1_all
				#N_ref1_all  += N_ini_ones_choice 

		print 'at final', N_ref1_all
		#print 'len weights 1', len(weights_1_for_IS_estimator_ref1),weights_1_for_IS_estimator_ref1
		#print 'len weights 0', len(weights_0_for_IS_estimator_ref1),weights_0_for_IS_estimator_ref1
		#print 'this should give the same', len(samples_all_ref1)
		ISestimator = ImportanceSampling_estimator_ref1(N_ref1_all,weights_1_for_IS_estimator_ref1)	
		ISestimator2 = ImportanceSampling_estimator_ref1((N_ref1_all+count_outside_parameter_space),weights_1_for_IS_estimator_ref1)
		print ' the IS estimator = ', ISestimator
		print 'the IS2 (with rejected) estimator = ',ISestimator2
		print 'number of merging BHs = ', len(M1_ref1_1)

		#print 'the IS estimator times N = ', ISestimator*N_ref1_all 
		estimator_error = estimator_error -0.2
			#print estimator_error
	print 'number of rejected samples = ', count_outside_parameter_space
	print 'total GWs in ref1 =', len(M1_ref1_1)
	#print weights_0_for_IS_estimator_ref1, 'sum w 0', sum(weights_0_for_IS_estimator_ref1)
	#print weights_1_for_IS_estimator_ref1, 'sum w 1', sum(weights_1_for_IS_estimator_ref1)
	return N_ref1_all,M1_ref1_1,a_ref1_1,q_ref1_1, M1_ref1_all,a_ref1_all,q_ref1_all,M1_ref1_BH,M2_ref1_BH,optimisticCEFlag_ref1,RLOFSecondaryAfterCEE_ref1

def calculates_mixturePDF(N_ini_1,gaus_mean_for_ref1,array,cov): #define as function once, instead of doing for loop so often
	''' '''
	#PDFx = np.zeros((N_hits_ini,len(array))) 
	PDFx = np.zeros((N_ini_1,1))
	#print 'PDFx start = ', PDFx 
	#print 'array = ',array
	for i in range(N_ini_1):
		PDFx[i,:] = (multivariate_normal.pdf(list(array),gaus_mean_for_ref1[i],cov))
	#print PDFx 
	#print 'PDFx end = ', PDFx 
	MixturePDFx = np.sum(PDFx,axis = 0) #*(float(N_ini_1))**-1 we take them out one Gaussian not out 5, so not normalize since we in both cases don't do this 
	#print 'mixturepdf =', MixturePDFx
	return MixturePDFx



#main program 

N_ini_ones_choice = 5
N_ini_all,M1_ini_1,a_ini_1,q_ini_1,M1_ini_all,a_ini_all,q_ini_all,gaus_mean_for_ref1, M1_BH,M2_BH,optimisticCEFlag,RLOFSecondaryAfterCEE,weights_ini_1 = initial_sampling(N_ini_ones_choice)

#fixed sample of 5: 
#N_ini_all = 474.
#M1_ini_1 = [np.array(50.7206), np.array(47.6808), np.array(50.5324), np.array(77.6881), np.array(80.4066)]
#a_ini_1 = [np.array(3.39383), np.array(2.1581), np.array(3.82603), np.array(8.03575), np.array(4.17658)]
#q_ini_1 = [0.80935556756032079, 0.51339742621768092, 0.90644220341800497, 0.76070466390605507, 0.83448995480470511]
#gaus_mean_for_ref1 = [[50.7206,3.39383,0.80935556756032079],[47.6808,2.1581,0.51339742621768092],[50.5324,3.82603,0.90644220341800497],[77.6881,8.03575,0.76070466390605507],[80.4066,4.17658,0.83448995480470511] ]

print 'the total number of intial samples = ', N_ini_all


MCestimator = MonteCarlo_estimator(N_ini_all,N_ini_ones_choice)
print 'The monte Carlo estimator equals', MCestimator
IS_estimator_ini = ImportanceSampling_estimator_ini(N_ini_all,weights_ini_1)
print 'The IS initial estimator equals', IS_estimator_ini

print 'hits', len(gaus_mean_for_ref1), gaus_mean_for_ref1
print M1_ini_1

N_ref1_all,M1_ref1_1,a_ref1_1,q_ref1_1, M1_ref1_all,a_ref1_all,q_ref1_all,M1_ref1_BH,M2_ref1_BH,optimisticCEFlag_ref1,RLOFSecondaryAfterCEE_ref1 = refined_1_sampling(N_ini_ones_choice,gaus_mean_for_ref1,N_ini_all)

M1plot =  [x for x in M1_ref1_all if x not in M1_ref1_1]
aplot = [x for x in a_ref1_all if x not in a_ref1_1]
qplot = [x for x in q_ref1_all if x not in q_ref1_1]
print 'N ini all = ', N_ini_all
print 'N ref1 all = ',N_ref1_all
print 'number of hits ref1 =', len(M1_ref1_1)

#np.savetxt('IS_ini_test2.out', np.c_[M1_ini_1,a_ini_1,q_ini_1, M1_BH,M2_BH,optimisticCEFlag,RLOFSecondaryAfterCEE,] )  
#np.savetxt('IS_ref1_test2.out', np.c_[M1_ref1_1,a_ref1_1,q_ref1_1, M1_ref1_BH,M2_ref1_BH,optimisticCEFlag_ref1,RLOFSecondaryAfterCEE_ref1] ) 
#np.savetxt('IS_ref1_test2.out', np.c_[M1_ref1_all,a_ref1_all,q_ref1_all])

# fig = plt.figure(1)
# #plt.subplot(222) 
# ax = fig.add_subplot(111, projection='3d') 
# ax.scatter(M1_ini_1,a_ini_1,q_ini_1,c='g', label = 'initial ones')
# ax.scatter(M1plot,aplot,qplot,c='b',label = 'ref1 all')
# ax.scatter(M1_ref1_1,a_ref1_1,q_ref1_1,c='r',label = 'ref1 ones')
# ax.legend()
# ax.set_xlabel('M1')
# ax.set_ylabel('a')
# ax.set_zlabel('q')
# plt.title('COMPAS importance sampling refinement')
# plt.show()

#plt.subplot(212) 
fig = plt.figure(2)
ax = fig.add_subplot(111, projection='3d') 
ax.scatter(M1_ini_1,a_ini_1,q_ini_1,c='g', label = 'initial ones')
ax.scatter(M1_ref1_1,a_ref1_1,q_ref1_1,c='r',label = 'ref1 ones')
ax.legend()
ax.set_xlabel('M1')
ax.set_ylabel('a')
ax.set_zlabel('q')
plt.title('COMPAS importance sampling refinement')
plt.show()
